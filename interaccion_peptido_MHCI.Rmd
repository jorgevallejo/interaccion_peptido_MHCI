---
title: "Predicción de interacción entre péptido y el complejo mayor de histocompatibilidad tipo I con Artificial Neural Networks (ANN) y Support Vector Machines (SVM)"
subtitle: "Machine Learning - PEC 2"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    number_sections: true
header-includes:
  - \renewcommand{\contentsname}{Sumario}
toc: true
# Next code for knitting more than one type of document automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all",
  output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE)

# This is a try:
knitr::opts_knit$set(stop_on_error = 2L)
# See ?evaluate::evaluate
# What I am trying to do is to make knitr stop
# when an error is found instead of running the
# complete script.
```

```{r delete results files, eval= FALSE}
# Run this chunk ONLY if you want to re-do
# all the report FROM ZERO.
# Remember that the .RData files are there to
# avoid unnecesarily redoing long data processing.

file.remove(c(""))


```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
```
\newpage

# Algoritmo Red Neuronal Artificial

Los algoritmos de Red Neuronal Artificial (o _ANN_ por el inglés _'Artificial Neuronal Net'_), son simulaciones que imitan el funcionamiento de las redes neuronales biológicas. Por lo general no modelan redes neuronales concretas, sino modelos abstractos.

Como abstracción de una red neural biológica, se podría decir que las ANNs constan de dos tipos de "piezas": **neuronas** y **nodos**.

- Las **neuronas** de las ANNs son objetos de código que - igual que hacen las neuronas biológicas - aceptan datos, los procesan, y envían datos a su vez.

- Los **nodos** son el equivalente a los axones y dendritas. Definen qué neuronas están conectadas entre ellas y, por tanto, cómo viaja la información dentro de la red neuronal.

Cada ANN se puede describir por las siguientes características:  
- La **función de activación**.  
- La **topología**.  
- El **algoritmo de entrenamiento**.

La **función de activación** describe la forma en que las neuronas combinan los datos que les llegan para generar los datos que envían. Diferentes funciones de activación son más adecuadas para diferentes tareas de aprendizaje. Las funciones más comunes son la _función de paso único_, la _lineal_, la _lineal saturada_, la _tangente hiperbólica_ y la _gaussiana_.

La **topología** de la red describe el número de neuronas por capa, el número de capas, y cómo se conectan unas con otras (número de nodos y si la información puede viajar "hacia atrás", de capas posteriores a capas anteriores).

El **algoritmo de entrenamiento** configura la forma en que se ponderan los datos que se transmiten por cada nodo, una forma de modular las señales que viajan por la red _adicional a la función de activación_.

## Fortalezas y debilidades de las Redes Neuronales Artificiales

|Fortalezas|Debilidades|
|----------------------------------------|----------------------------------------|
| - Se pueden usar tanto para problemas de clasificación como para predicción numérica. | - Necesitan enormes cantidades de recursos de cálculo y su entrenamiento es lento, especialmente cuando la topología de la red es compleja|
|||
| - Pueden modelar patrones más complejos que casi cualquier otro algoritmo. | - Muy susceptibles a sobreajustar los datos de entrenamiento. |
|||
| - Hace pocas asunciones previas acerca de las relaciones entre los datos. | - El modelo resultante del entrenamiento es de tipo caja negra, complejo y difícil (si no imposible) de interpretar. |

# Algoritmo Support Vector Machine

Los algoritmos SVM (_Support Vector Machine_) procesan datos distribuidos en un espacio multidimensional, y los utilizan para definir una superficie (hiperplano) que divide dicho espacio en regiones homogéneas que agrupan observaciones afines. Estos algoritmos se usan en el campo del aprendizaje automático tanto para clasificar observaciones, como para hacer predicciones. Este pequeño script pondrá en aplicación una de sus funciones más sencillas, la clasificación de un conjunto de observaciones en dos grupos diferenciados.

Cuando las observaciones de ambos grupos están claramente separadas y pueden separarse completamente mediante una línea, plano, o su equivalente multidimensional (hiperplano), hablamos de **datos separables linealmente**. Sin embargo, en la vida real es muy común que la relación entre variables no sea lineal. Es estos casos, se pueden seguir dos estrategias: aplicación de la _slack variable_ (variable fluctuante) y el uso del _kernel trick_ (cambio de la función kernel).

El caso de la variable _slack_ consiste en añadir una variable el algoritmo que "permite" dejar observaciones de entrenamiento fuera del grupo al que propiamente pertenecen. Aquí lo que produce el algoritmo es una optimización del hiperplano para miniminar la distancia de esas observaciones hasta el límite que define su clasificación correcta.

El _kernel trick_ es matemáticamente más complejo y consiste en añadir nuevas dimensiones a los datos y usarlas para identificar las relaciones no lineales entre las variables. Aquí las superficies que definen los límites entre grupos ya no son hiperplanos, sino curvas de mayor o menor complejidad.

## Fortalezas y debilidades del algoritmo SVM

|Fortalezas|Debilidades|
|----------------------------------------|----------------------------------------|
| - Se puede usar tanto para problemas de clasificación como para predicción numérica. | - Encontrar el modelo más adecuado requiere probar varias combinaciones de kernels y parámetros. |
|||
| - Poco sensible al ruido en los datos y poco propenso al sobreajuste (overfitting). | - El entrenamiento puede ser lento, en especial se el set de datos tiene un gran número de características o ejemplos. |
|||
| - Puede ser de más fácil uso que las redes neurales, especialmente debido a la existencia de varios algoritmos SVM que han sido adaptados para su uso en ciencia de datos. | - El modelo resultante del entrenamiento es de tipo caja negra, complejo y difícil (si no imposible) de interpretar. |
|||
| - Popular debido a su alta precisión y a la fama debida a su uso ganador en competiciones de minería de datos. | |